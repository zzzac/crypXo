{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4e02947",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ccxt\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d84a9c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Êï∞ÊçÆÊ†ºÂºèÔºö\n",
    "# symbol, exc, ts, timestamp, open, high, low, close, volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df0b961",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import ccxt\n",
    "import boto3\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from datetime import datetime, timezone, timedelta\n",
    "\n",
    "# === CONFIG ===\n",
    "START_DATE = '2020-01-01'\n",
    "INTERVAL = '1m'\n",
    "BUCKET = 'crypto.kline.data'\n",
    "LOCAL_TMP_DIR = './data'\n",
    "SYMBOL_DIR = 'symbols.txt'\n",
    "\n",
    "# AWS client\n",
    "s3 = boto3.client('s3')\n",
    "exchange = ccxt.binance({\n",
    "    'options': {\n",
    "        'defaultType': 'future'  # ÂÖ≥ÈîÆÔºöÊåáÂÆö‰∏∫ futuresÔºå‰∏çÊòØ spotÔºÅ\n",
    "    }\n",
    "})\n",
    "# markets = exchange.load_markets()\n",
    "symbol = 'BTC/USDT'\n",
    "# market = exchange.market(symbol)\n",
    "\n",
    "# === HELPERS ===\n",
    "def ensure_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "def read_symbols(loc):\n",
    "    with open(loc, 'r') as f:\n",
    "        symbols = f.readlines()\n",
    "    return [i.strip() for i in symbols if len(i.strip()) > 0]\n",
    "\n",
    "# def s3_file_exists(symbol, day):\n",
    "#     normalized_symbol = symbol.replace(\"/\", \"-\")\n",
    "#     s3_key = f\"{exchange.id}/{INTERVAL}/{normalized_symbol}/{day}.parquet\"\n",
    "#     try:\n",
    "#         s3.head_object(Bucket=BUCKET, Key=s3_key)\n",
    "#         return True\n",
    "#     except s3.exceptions.ClientError as e:\n",
    "#         if e.response['Error']['Code'] == \"404\":\n",
    "#             return False\n",
    "#         raise\n",
    "\n",
    "def fetch_day_ohlcv(symbol, since_ts, until_ts):\n",
    "    all_candles = []\n",
    "    ts = since_ts\n",
    "    while ts < until_ts:\n",
    "        try:\n",
    "            candles = exchange.fetch_ohlcv(symbol, timeframe=INTERVAL, since=ts, limit=1000)\n",
    "            if not candles:\n",
    "                break\n",
    "            for c in candles:\n",
    "                if c[0] >= until_ts:\n",
    "                    break\n",
    "                all_candles.append(c)\n",
    "            ts = candles[-1][0] + 60_000\n",
    "            time.sleep(0.25)\n",
    "        except Exception as e:\n",
    "            print(f\"[Error] {symbol} @ {datetime.fromtimestamp(ts / 1000, timezone.utc)} : {e}\")\n",
    "            time.sleep(3)\n",
    "    return all_candles\n",
    "\n",
    "def save_daily_parquet_to_s3(symbol, day, candles):\n",
    "    if not candles:\n",
    "        print(f\"[‚ö†Ô∏è Empty] No data for {symbol} on {day}\")\n",
    "        return\n",
    "\n",
    "    normalized_symbol = symbol.replace(\"/\", \"-\")\n",
    "    s3_key = f\"{exchange.id}/{INTERVAL}/{normalized_symbol}/{day}.parquet\"\n",
    "    local_path = os.path.join(LOCAL_TMP_DIR, s3_key.replace(\"/\", \"_\"))\n",
    "    ensure_dir(os.path.dirname(local_path))\n",
    "\n",
    "    table = pa.Table.from_arrays(\n",
    "        [\n",
    "            pa.array([row[0] for row in candles], type=pa.int64()),     # timestamp\n",
    "            pa.array([row[1] for row in candles], type=pa.float64()),   # open\n",
    "            pa.array([row[2] for row in candles], type=pa.float64()),   # high\n",
    "            pa.array([row[3] for row in candles], type=pa.float64()),   # low\n",
    "            pa.array([row[4] for row in candles], type=pa.float64()),   # close\n",
    "            pa.array([row[5] for row in candles], type=pa.float64()),   # volume\n",
    "            pa.array([symbol] * len(candles)),                          # symbol\n",
    "            pa.array([exchange.id] * len(candles)),                     # exchange\n",
    "            pa.array([INTERVAL] * len(candles)),                        # interval\n",
    "        ],\n",
    "        names=[\"timestamp\", \"open\", \"high\", \"low\", \"close\", \"volume\", \"symbol\", \"exchange\", \"interval\"]\n",
    "    )\n",
    "\n",
    "    pq.write_table(table, local_path, compression='snappy')\n",
    "    s3.upload_file(local_path, BUCKET, s3_key)\n",
    "    print(f\"[S3 ‚úÖ] {symbol} {day} ‚Üí {s3_key}\")\n",
    "\n",
    "\n",
    "def save_daily_parquet_to_local(symbol, day, candles):\n",
    "    if not candles:\n",
    "        print(f\"[‚ö†Ô∏è Empty] No data for {symbol} on {day}\")\n",
    "        return\n",
    "\n",
    "    normalized_symbol = symbol.replace(\"/\", \"-\")\n",
    "    local_path = f\"{LOCAL_TMP_DIR}/{exchange.id}/{INTERVAL}/{normalized_symbol}/{day}.parquet\"\n",
    "    ensure_dir(os.path.dirname(local_path))\n",
    "\n",
    "    table = pa.Table.from_arrays(\n",
    "        [\n",
    "            pa.array([row[0] for row in candles], type=pa.int64()),     # timestamp\n",
    "            pa.array([row[1] for row in candles], type=pa.float64()),   # open\n",
    "            pa.array([row[2] for row in candles], type=pa.float64()),   # high\n",
    "            pa.array([row[3] for row in candles], type=pa.float64()),   # low\n",
    "            pa.array([row[4] for row in candles], type=pa.float64()),   # close\n",
    "            pa.array([row[5] for row in candles], type=pa.float64()),   # volume\n",
    "            pa.array([symbol] * len(candles)),                          # symbol\n",
    "            pa.array([exchange.id] * len(candles)),                     # exchange\n",
    "            pa.array([INTERVAL] * len(candles)),                        # interval\n",
    "        ],\n",
    "        names=[\"timestamp\", \"open\", \"high\", \"low\", \"close\", \"volume\", \"symbol\", \"exchange\", \"interval\"]\n",
    "    )\n",
    "\n",
    "    pq.write_table(table, local_path, compression='snappy')\n",
    "\n",
    "\n",
    "# === MAIN ===\n",
    "def main():\n",
    "    ensure_dir(LOCAL_TMP_DIR)\n",
    "    symbols = read_symbols(SYMBOL_DIR)\n",
    "    start_date = datetime.strptime(START_DATE, '%Y-%m-%d').date()\n",
    "    end_date = datetime.now(timezone.utc).date()\n",
    "\n",
    "    for symbol in symbols:\n",
    "        print(f\"==> Processing {symbol}\")\n",
    "        current_date = end_date\n",
    "        while current_date >= start_date:\n",
    "            day_str = current_date.isoformat()\n",
    "            # if s3_file_exists(symbol, day_str):\n",
    "            #     print(f\"[üõë Skip] {symbol} {day_str} already exists in S3\")\n",
    "            #     current_date -= timedelta(days=1)\n",
    "            #     continue\n",
    "            since_ts = int(datetime.combine(current_date, datetime.min.time(), tzinfo=timezone.utc).timestamp() * 1000)\n",
    "            until_ts = since_ts + 24 * 60 * 60 * 1000\n",
    "            print(f\"[üì• Fetching] {symbol} {day_str}\")\n",
    "            candles = fetch_day_ohlcv(symbol, since_ts, until_ts)\n",
    "            # save_daily_parquet_to_s3(symbol, day_str, candles)\n",
    "            save_daily_parquet_to_local(symbol, day_str, candles)\n",
    "            current_date -= timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0a3441f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Processing BTC/USDT\n",
      "[üì• Fetching] BTC/USDT 2025-07-27\n"
     ]
    }
   ],
   "source": [
    "exchange = ccxt.binance()\n",
    "# markets = exchange.load_markets()\n",
    "symbol = 'BTC/USDT'\n",
    "\n",
    "start_date = datetime.strptime(START_DATE, '%Y-%m-%d').date()\n",
    "end_date = datetime.now(timezone.utc).date()\n",
    "\n",
    "print(f\"==> Processing {symbol}\")\n",
    "current_date = end_date\n",
    "\n",
    "day_str = current_date.isoformat()\n",
    "since_ts = int(datetime.combine(current_date, datetime.min.time(), tzinfo=timezone.utc).timestamp() * 1000)\n",
    "until_ts = since_ts + 24 * 60 * 60 * 1000\n",
    "print(f\"[üì• Fetching] {symbol} {day_str}\")\n",
    "candlesspot = fetch_day_ohlcv(symbol, since_ts, until_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2aacf032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Processing BTC/USDT\n",
      "[üì• Fetching] BTC/USDT 2025-07-27\n"
     ]
    }
   ],
   "source": [
    "exchange = ccxt.binance({\n",
    "    'options': {\n",
    "        'defaultType': 'future'  # ÂÖ≥ÈîÆÔºöÊåáÂÆö‰∏∫ futuresÔºå‰∏çÊòØ spotÔºÅ\n",
    "    }\n",
    "})\n",
    "# markets = exchange.load_markets()\n",
    "symbol = 'BTC/USDT'\n",
    "\n",
    "symbol = 'BTC/USDT'\n",
    "start_date = datetime.strptime(START_DATE, '%Y-%m-%d').date()\n",
    "end_date = datetime.now(timezone.utc).date()\n",
    "\n",
    "print(f\"==> Processing {symbol}\")\n",
    "current_date = end_date\n",
    "\n",
    "day_str = current_date.isoformat()\n",
    "since_ts = int(datetime.combine(current_date, datetime.min.time(), tzinfo=timezone.utc).timestamp() * 1000)\n",
    "until_ts = since_ts + 24 * 60 * 60 * 1000\n",
    "print(f\"[üì• Fetching] {symbol} {day_str}\")\n",
    "candles = fetch_day_ohlcv(symbol, since_ts, until_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a30c644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[1753574400000, 117889.3, 117926.0, 117889.2, 117912.1, 39.633],\n",
       "  [1753574460000, 117912.1, 117912.1, 117862.3, 117862.3, 29.205],\n",
       "  [1753574520000, 117862.4, 117880.0, 117862.3, 117871.1, 63.438],\n",
       "  [1753574580000, 117871.2, 117871.2, 117862.3, 117862.3, 27.468],\n",
       "  [1753574640000, 117862.3, 117862.4, 117855.0, 117855.1, 23.978]],\n",
       " [[1753574400000, 117919.99, 117952.12, 117919.99, 117947.74, 2.34686],\n",
       "  [1753574460000, 117947.74, 117947.74, 117901.7, 117901.7, 4.25359],\n",
       "  [1753574520000, 117901.7, 117910.54, 117901.7, 117910.53, 0.87761],\n",
       "  [1753574580000, 117910.53, 117910.54, 117891.9, 117891.9, 3.7089],\n",
       "  [1753574640000, 117891.9, 117891.91, 117891.89, 117891.89, 1.04697]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candles[:5], candlesspot[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "543425b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1. ETH/USDT     Volume: 2,042,389,459.99\n",
      " 2. BTC/USDT     Volume: 2,016,684,682.47\n",
      " 3. USDC/USDT    Volume: 1,117,361,857.83\n",
      " 4. XRP/USDT     Volume: 446,798,143.69\n",
      " 5. FDUSD/USDT   Volume: 435,025,101.63\n",
      " 6. SOL/USDT     Volume: 420,366,199.46\n",
      " 7. PEPE/USDT    Volume: 263,862,716.23\n",
      " 8. DOGE/USDT    Volume: 213,654,307.53\n",
      " 9. SUI/USDT     Volume: 132,874,674.55\n",
      "10. BONK/USDT    Volume: 132,773,980.50\n",
      "11. UNI/USDT     Volume: 121,399,320.20\n",
      "12. BNB/USDT     Volume: 90,626,088.13\n",
      "13. ADA/USDT     Volume: 89,923,554.22\n",
      "14. SAHARA/USDT  Volume: 89,391,994.90\n",
      "15. XLM/USDT     Volume: 77,298,990.40\n",
      "16. WIF/USDT     Volume: 76,395,926.74\n",
      "17. HYPER/USDT   Volume: 68,905,896.32\n",
      "18. TRUMP/USDT   Volume: 66,226,899.81\n",
      "19. PENGU/USDT   Volume: 66,032,115.87\n",
      "20. NEIRO/USDT   Volume: 61,651,370.47\n",
      "21. MAGIC/USDT   Volume: 60,806,227.20\n",
      "22. BANANAS31/USDT Volume: 59,784,635.56\n",
      "23. AAVE/USDT    Volume: 58,885,155.14\n",
      "24. LA/USDT      Volume: 57,640,814.71\n",
      "25. AVAX/USDT    Volume: 52,996,954.03\n",
      "26. ENA/USDT     Volume: 52,882,886.64\n",
      "27. EUR/USDT     Volume: 52,506,588.54\n",
      "28. TRX/USDT     Volume: 51,782,269.00\n",
      "29. LINK/USDT    Volume: 51,135,819.91\n",
      "30. LTC/USDT     Volume: 45,451,971.85\n",
      "31. PNUT/USDT    Volume: 44,226,173.21\n",
      "32. ETHFI/USDT   Volume: 41,832,074.08\n",
      "33. SEI/USDT     Volume: 39,351,359.06\n",
      "34. VIRTUAL/USDT Volume: 37,642,504.47\n",
      "35. HBAR/USDT    Volume: 36,026,464.59\n",
      "36. ARB/USDT     Volume: 34,031,236.06\n",
      "37. FLOKI/USDT   Volume: 33,647,512.30\n",
      "38. TAO/USDT     Volume: 29,263,833.97\n",
      "39. GMX/USDT     Volume: 28,195,536.33\n",
      "40. WLD/USDT     Volume: 26,837,189.64\n",
      "41. OP/USDT      Volume: 26,147,333.96\n",
      "42. COMP/USDT    Volume: 26,126,284.36\n",
      "43. TIA/USDT     Volume: 25,521,976.16\n",
      "44. VIC/USDT     Volume: 25,379,184.39\n",
      "45. NEAR/USDT    Volume: 24,787,874.52\n",
      "46. SHIB/USDT    Volume: 24,543,762.84\n",
      "47. APT/USDT     Volume: 23,871,335.99\n",
      "48. CRV/USDT     Volume: 23,223,261.89\n",
      "49. AIXBT/USDT   Volume: 23,142,632.14\n",
      "50. BCH/USDT     Volume: 22,098,151.51\n"
     ]
    }
   ],
   "source": [
    "def get_volumes_by_exc(exchange, pairs):\n",
    "    res = []\n",
    "    split = 50\n",
    "    for k in range(len(pairs)//split + 1):\n",
    "        pair = pairs[split*k : split*k+split]\n",
    "        tickers = exchange.fetch_tickers(pair)\n",
    "\n",
    "        volumes = [\n",
    "            (symbol, ticker['quoteVolume'])\n",
    "            for symbol, ticker in tickers.items()\n",
    "            if ticker.get('quoteVolume')\n",
    "        ]\n",
    "        res += volumes\n",
    "    return res\n",
    "\n",
    "# ‰ΩøÁî® ccxt Ëá™Âä®Â§ÑÁêÜ fetch_tickersÔºàÂÆÉ‰ºöÊãÜÂàÜËØ∑Ê±ÇÔºâ\n",
    "markets = exchange.load_markets()\n",
    "\n",
    "# Âè™ÂèñÁé∞Ë¥ß USDT ‰∫§ÊòìÂØπ\n",
    "usdt_pairs = [s for s in markets if s.endswith('/USDT') and not markets[s]['contract']]\n",
    "\n",
    "\n",
    "volumes = get_volumes_by_exc(exchange, usdt_pairs)\n",
    "\n",
    "top_50 = sorted(volumes, key=lambda x: x[1], reverse=True)[:50]\n",
    "\n",
    "# ËæìÂá∫\n",
    "for i, (symbol, volume) in enumerate(top_50, 1):\n",
    "    print(f\"{i:2d}. {symbol:12s} Volume: {volume:,.2f}\")\n",
    "\n",
    "\n",
    "symbols = [symbol for (symbol, volume) in top_50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ebbef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('symbols.txt', 'w') as f:\n",
    "    f.write('\\n'.join(symbols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef11f55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2912e5db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d2cad3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
